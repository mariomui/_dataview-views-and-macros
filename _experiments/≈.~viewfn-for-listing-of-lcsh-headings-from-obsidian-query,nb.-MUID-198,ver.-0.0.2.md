---
CREATION_DATE: 2025-05-16
DEPENDENCIES:
  - "[[macro-for-updating-meta-heading-endpoints,vis-Noteshippo,nb.-MUID-152,ver-v0.0.2]]"
  - "[[macro-for-inserting-base-filepath,nb.-MUID-161,ver.-v0.0.9]]"
DOC_VERSION: v0.0.2
MUID: MUID-198
PROJECT_PARENT: "[[≈-how-to-solve-the-freqenct-LCSH-reassignment-problem,vis-Noteshippo?]]"
TEMPLATE_SOURCE: "[[10--nascent-spec-template]]"
TEMPLATE_VERSION: v1.0.14
tags:
  - _misc/_wip
---

# -

## 00-Meta

> [!info]+ Progress Bar
> > ![[~view-for-local-tasks-using-a-progress-bar,nb.-MUID-698#=|olk]]
> ```dataview
> task where file.name = this.file.name and !completed
> ```
> >
> ```dataview
> task where file.name = this.file.name and completed
> ```

### 10÷About

* ! Oh crap I can't change the title on partials cuz they are inside the goddamn block

### 11÷Reference

* [[macro-for-prompted-scraping-for-specific-filename-using-embedded-query,ver.-v0.0.2,uti.-MUID-1934A]]
## 20-Inlink

> [!abstract]- %%  %% Automated List of Reference Inlinks (v0.0.5)
> * ℹ Commit/design logs are located in this [[,aka-MUID-150|experiment note]].
> >`= join( map( sort( map( filter(this.file.inlinks, (link) => meta(link).path != this.file.path), (x) => [ split(meta(x).path, "/")[length(split(meta(x).path, "/")) - 1], x ] ) ), (b) => "• " + choice( length(b[0]) > 28, link( b[1], truncate( regexreplace(b[0], "(-of|of|the|-the|-for|-that|https-|ee)", ""), length( regexreplace(b[0], "(-of|of|the|-the|-for|-that|https-|ee)", "") ) * 0.75 ) ), link(b[1], regexreplace(b[0], "\.md$", "")) ) ), "<br>" )`

# =

**base_filepath-v0.0.6**: `= choice( contains(this.file.folder, this.file.name), link(this.file.path), join(["*",this.file.path,"*"], ""))` doc-`= this.DOC_VERSION` / ids: `= this.MUID`,PP:`= this.PROJECT_PARENT` / lcsh: `= link(this.heading)`

* Add the search_term for the query in the arguments like so `|?search_term=...`
~~~dataviewjs
const ACTIVE_DEBUG = true; // todo , extract this prop from the consuming file.
const { default: obs } =
  this.app.plugins?.plugins?.["templater-obsidian"]?.templater
    ?.current_functions_object?.obsidian;

const {metadataCache,vault,workspace,fileManager} = this.app
const {adapter} = vault;

let SEARCH_TERM = "---Transient Local Query";

const getCFP = () => this.currentFilePath;

const debug = (...args) => {
  if (ACTIVE_DEBUG) {
    console.log.call(console, ...args)
  }
}
workspace.onLayoutReady(main.bind(this))
function main(cmd) {
 if (!obs) return;

 (genMain)(this,renderUI.bind(this))

  async function genMain(ctx,renderUI) {
    // --
    const providing_path = getCFP()
    const argMap = extractParams(
      providing_path,
      workspace.getActiveFile()
    )
    debug({providing_path,argMap})

    SEARCH_TERM = argMap.search_term || SEARCH_TERM;

    // --

    const avf = workspace.getActiveFile()
    const mdc = metadataCache.getFileCache(avf)
    const avfv = workspace.getActiveFileView()

    // scrape links from the obsidian query
    const queryFileFigsPayload = await genProcessQueriedFileFigsByActiveFileView(avfv, SEARCH_TERM)
    debug({queryFileFigsPayload})

    
    const {
      unaliasedQueryLinks,
      unaliasedEmbeddedLinks
    } = await genProcessDiffingArtifactFig(mdc,queryFileFigsPayload)
    debug({unaliasedQueryLinks, unaliasedEmbeddedLinks})
		
		const [frontmatterHeadings, unused_query_links] = getFrontmatterHeadingFigUsed(
			unaliasedQueryLinks
		);

		const mapToMarkdownPredicate = (base_name) => {
			const markdownLink = getMarkdownLink(
				metadataCache.getFirstLinkpathDest(base_name)
			);
			if (!markdownLink) {
				debug({markdownLink, base_name})
				return `<span class="internal-link is-unresolved">${base_name}</span>`
			}
			return markdownLink
		}
		const renderableMatrix = transformDataToRenderable(
			frontmatterHeadings, 
			unused_query_links, 
			mapToMarkdownPredicate
		);
		debug({frontmatterHeadings, argMap, renderableMatrix}, unused_query_links)
		
		/**
		 * @param lcshMap {Map<string, Set<string>>}
		 * @return Array<markdown_link, markdown_link[]>|T
		 * */
		function transformDataToRenderable(
			lcshMap,
			base_names, 
			cb = (x) => x,
		) {
		
			const normaledTuples = Array.from(lcshMap).map(([k,v]) => {
				
				// transform Set to markdown_links.
				const markdown_linkified_base_names = Array.from(v).map(cb);

				const markdown_link_key = cb(k);
				if (markdown_linkified_base_names.length === 1) {
					if (markdown_linkified_base_names.first() === markdown_link_key) {
						return markdown_link_key;
					}
				}
				return [markdown_link_key, markdown_linkified_base_names]
			})
			return normaledTuples.sort().concat(
				base_names.map(mapToMarkdownPredicate)
			);
		}


		
		// ## LOGIC: grab the headings into a fig.
	  function getFrontmatterHeadingFigUsed(base_names) {
		  const lcshMap = new Map();
		  const no_heading_base_names = []
		  for (const base_name of base_names) {
			  const vf = metadataCache.getFirstLinkpathDest(base_name,"")
				const cache = metadataCache.getFileCache(vf);
				// debug({cache})
				const fmHeading = cache?.frontmatter?.heading
				if (!fmHeading) {
					no_heading_base_names.push(base_name);
					continue;
				}
				if ( Array.isArray(fmHeading) ) {
					cache.frontmatter.heading.forEach((lcsh) => {
						updateMap(lcshMap, lcsh, base_name)
					})
					continue;
				}
				if ( typeof fmHeading === "string") {
					updateMap(lcshMap, fmHeading, base_name)
				}
				function updateMap(lcshMap, lcsh, base_name) {
					if (lcshMap.has(lcsh) === false) {
						lcshMap.set(lcsh, new Set([base_name]))
					} 
					if (lcshMap.has(lcsh)) {
						lcshMap.get(lcsh).add(base_name)
					}
				}

				
		  }
			return [lcshMap, no_heading_base_names];
	  }
	  
    //ui
    renderRefreshAndCopyButton.call(ctx, main,"copy")

    if (renderableMatrix.length >= 1) {
      
      return renderUI.call(ctx, renderableMatrix, cmd)
    }  

    const { $el } = await genCreateDiv(
      ctx, { text: "" , cls: "deleteme"}
    );

    const callout_text = getTextForRender(argMap?.search_term || "Empty"); 
    const rendered_text = await obs.MarkdownRenderer.render(
      ctx.app,
      callout_text,
      $el,
      "",
      ctx.container.component
    );
    ctx.container.append($el)

  }
}

//take the links from the query and process it.
/**
@param queryFileFigsPayload {data: VFs, err: string | null}
**/
async function genProcessDiffingArtifactFig(mdc, queryFileFigsPayload) {
   
  const embeddedLinks = processAllEmbeddedLinks(mdc);
  const config = queryFileFigsPayload;
  if (!config?.data) return manuProcessDiffJobLineFig();
  debug({embeddedLinks, config})
  const unaliasedEmbeddedLinks = await genProcessMarkdownLinksByWikiLink(embeddedLinks)
  const unaliasedQueryLinks = await genProcessMarkdownLinksByVf(config.data);

  return  {
    unaliasedEmbeddedLinks,
    unaliasedQueryLinks
  }
  // compare the links in the note will have less text than the ones in the query.
}

function manuProcessDiffJobLineFig() {
  return {
    unaliasedQueryLinks: [],
    unaliasedEmbeddedLinks: []
  }
}
function processDiffJobLine(
  fig = manuProcessDiffJobLineFig()
) {
  const config = Object.assign({}, manuProcessDiffJobLineFig(), fig);
  const { unaliasedQueryLinks, unaliasedEmbeddedLinks} = config
  debug({unaliasedQueryLinks, unaliasedEmbeddedLinks})
  const unusedLinks = []
  for (const link of unaliasedQueryLinks) {
    const isUsed = unaliasedEmbeddedLinks.some(
      (embedLink) => {
        //debug({link, embedLink})
        const isAccepted = (link.length - embedLink.length) * 1 < 2;
        return link.startsWith(embedLink) && isAccepted
      }
    )
    if (!isUsed) {
      unusedLinks.push(link)
    }
  }
  return unusedLinks;
}

async function genScrapeTextFromWikiLink(wikilink) {
  return new Promise((rs,rj) => { 
    wikilink.replace(/\[\[(.*?)\]\]/g, (match, data) => {
      if (data) {
        rs({data, err: null})
      } else {
        rj({data: null, err: `ERR: data is ${data||"N/A"}`})
      }
      return match
    }) 
  })
}
async function genProcessMarkdownLinksByWikiLink(wikilinks) {
  if (!Array.isArray(wikilinks)) return [];
  const unaliasedMarkdownLinks = []
  for (const wikilink of wikilinks) {
    const unaliasedMdLink = await genUnaliasedMarkdownLink(wikilink)
    if (unaliasedMdLink) {
     unaliasedMarkdownLinks.push(unaliasedMdLink)
    } else {
     debug({unaliasedMdLink}, wikilinks)
    }
  }
  return unaliasedMarkdownLinks
}

async function genProcessMarkdownLinksByVf(vfs = []) {
  if (!Array.isArray(vfs)) return [];
  const unaliasedMarkdownLinks = []
  debug({vfs})
  for (const datum of vfs) {
    const markdownLink = getMarkdownLink(datum, datum.basename)
    const unaliasedMdLink = await genUnaliasedMarkdownLink(markdownLink)
    unaliasedMarkdownLinks.push(unaliasedMdLink)
  }
  return unaliasedMarkdownLinks
}

// utils
function getMarkdownLink(avf,heading) {

  const _embed_text = !heading ? "" : `#${heading}`
  if (!avf) return null;
  const markdownLink = fileManager
    .generateMarkdownLink(
      avf,
      avf.path,
      avf.basename + _embed_text,
      heading
    )
  return markdownLink;
}

async function genUnaliasedMarkdownLink(markdownLink) {
    const payload = await genScrapeTextFromWikiLink(
      markdownLink
    )
    if (payload?.err) {
      debug({err})
      dv.paragraph("fucking error")
      return "";
    }
    const parsedLink = obs.parseLinktext(payload.data);
 
    // if (parsedLink?.path) {
    return parsedLink.path
    // }
  // debug({parsedLink, payload})
    // throw new Error("Parsed path does not exist ")
}

// # processors
async function genProcessQueryFileFigToWikiLinks(fileFig) {
  
  const markdownLink = getMarkdownLink(avf,heading)
  try {
    const unaliasedMarkdownLink = await genUnaliasedMarkdownLink(markdownLink);
    return unaliasedMarkdownLink
  } catch(err) {
    const err_string = JSON.stringify(err);
    throw new Error(`genUnaliasedMarkdownLink error ${err_string}`)
  }
}

function processAllEmbeddedLinks(mdc) {


  const mdcLinks = mdc?.links?.map(({original}) => original) || [];
  const mdcEmbeds = mdc?.embeds?.map(({original}) => original) || [];
  const mdcs = [...mdcLinks, ...mdcEmbeds]
  return mdcs;
}


async function genProcessQueriedFileFigsByActiveFileView(avf, search_term) {
  // I couldnt find a callback to see when the queue finished populating but when i do i knwo this function will need it.
  return new Promise((rs,rj) => {
    {var result = { data: [], err: null};
    
      try {
        const data = avf?.
          _children?.at(0)?._children
            ?.find((child) => child.query && child.query.indexOf(search_term) > -1)
            ?.dom?.getFiles()
        result.data = data || []
        return rs(result)
      } catch (err) {
        result.err = err;
        return rj(result)
      }
    }
  })
}

// # UI

function getTextForRender(search_term) {
      const warning =  `\> [!warning] Search_term is empty`
      const notification =  `\> [!note] ${search_term} has been used up`;
      if (!search_term) return warning;
}

function renderRefreshAndCopyButton(main,cmd) {
  const copy = cmd === "copy" ? "copy" : null
  const handleClick = () => {
    const $button = this.container.querySelector('button')
    $button.remove();
    this.container?.lastChild?.remove();
    main.call(this, copy);

  }
  new obs
    .ButtonComponent(this.container)
    .setButtonText('Refresh and Copy')
    .onClick(handleClick.bind(this))
}


function renderUI(renderableMatrix, cmd) {
		let ui_md_text = ""
		for (const tuple of renderableMatrix) {
			if (typeof tuple === "string") {
				ui_md_text += `* ${tuple}\n`;

			} 
			if (Array.isArray(tuple)) {
				const [k,v] = tuple;
				ui_md_text += `* ${k}\n`;
				ui_md_text += (covertToBulletedText(v, "\t"));
			}
		}

		function covertToBulletedText(embed_texts, spacing) {
			const ui_md_text = embed_texts.reduce((chain,text, idx) => {
				const newline = idx < embed_texts.length ? "\n" : 0
			  return chain + `${spacing}* ` + text + newline;
			},"")
			return ui_md_text;
		}

		/// specific rendering text;
    const $el =dv.paragraph(
      ui_md_text, {
        cls: "deleteme"
      }
    );
		const cls = {cls: "deleteme"};
		// const $el = dv.list(renderableMatrix, cls);
    if (cmd === "copy")  {
      const text = $el.innerText;
      navigator.clipboard.writeText(ui_md_text);
    }
}

function genCreateFrag(ctx) {
  return new Promise((resolve, rej) => {
    ctx.container.win.createFragment(($el) => {
      ctx.app.workspace.onLayoutReady(() => {
        resolve({$el})
      })
    })
  })
}
async function genCreateDiv(ctx, config = {text: ''}) {
  const {text} = config;
  const $frag = await genCreateFrag(ctx);
  return new Promise((resolve, reject) => {
    const domInfo = {
      text,
      parent: $frag
    };
    ctx.container.win.createDiv(domInfo, callback)
    function callback($el) {
      ctx.app.workspace.onLayoutReady(() => {
        resolve({$el, $frag})
      })
    }
  })
}

// # Extraction Code vX.X.X.
// impossible to version when inside another codelet.
function manuParams() {
  return {
    search_term: "",
    regex_flag: "g"
  }
}
function extractParams(
  current_filepath,
  vf
) {

  const embeds = getEmbedsFromVf(vf)
  const {name} = vault.adapter.path
    .parse(current_filepath);
  const embed = extractTargetEmbed(
    name,
    embeds
  );
  const displayText = embed?.displayText;

  debug({name, embed})

  if (!displayText) {
    return manuParams()
  };

  const argMap = parseStringToMap(
    displayText
  );
  return {
    ...manuParams(),
    ...argMap
  };
  // /end params extraction

  // helpers
  function getEmbedsFromVf(vf) {
    return metadataCache
      .getFileCache(vf)?.embeds || [];
  }

  function extractTargetEmbed(
    embed_name,
    embeds
  ) {
    const embed = embeds?.find(
    (embed) => {
      const parsed = obs.parseLinktext(
        embed.link
      );
	    debug({embed, embed_name, parsed})
      return parsed.path === embed_name;
    });
    return embed;
  }


	function parseStringToMap(query_str) {
		{ var parsed = {};
			try {
			debug({query_str})
				const fixed_query = query_str.replace(/\+/g, '%2B'); // + signs are no bueno.
				// const fixed_query = query_str;
	
				parsed = adapter
					?.url
					?.parse(fixed_query, true);
				// url parse is deprecated but its still useful and fast.
			} catch (err) {
	
				return {
					err
				}
			}
			debug({parsed})
			return parsed?.query || {};
		}
		return {};
	}
}
~~~

# ---Transient

# ---Tranisent Commit Log

* v0.0.2
	* Add instructions for use
	* [ ] Create a codelet for lcsh specced notes that queues up reassignment. See the project experiment file of MUID-198 for further details. ➕ 2025-05-20 #_todo/to-code
